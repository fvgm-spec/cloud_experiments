{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's [AWS SDK for pandas](https://aws-sdk-pandas.readthedocs.io/en/stable/about.html)?\n",
    "\n",
    "An AWS Professional Service open source python initiative that extends the power of the pandas library to AWS, connecting DataFrames and AWS data & analytics services.\n",
    "\n",
    "Easy integration with Athena, Glue, Redshift, Timestream, OpenSearch, Neptune, QuickSight, Chime, CloudWatchLogs, DynamoDB, EMR, SecretManager, PostgreSQL, MySQL, SQLServer and S3 (Parquet, CSV, JSON and EXCEL).\n",
    "\n",
    "Built on top of other open-source projects like Pandas, Apache Arrow and Boto3, it offers abstracted functions to execute your usual ETL tasks like load/unloading data from Data Lakes, Data Warehouses and Databases, even at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import awswrangler as wr\n",
    "import yfinance as yf\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting datetime variables\n",
    "today = dt.datetime.now()                #Current day of the month\n",
    "start_date = today - timedelta(days=365) #1 year back from the current day\n",
    "end_date = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Location\": \"http://aws-sdk-pandas72023.s3.amazonaws.com/\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Creating S3 bucket using AWS CLI\n",
    "!aws s3api create-bucket --bucket aws-sdk-pandas72023 --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the variable for the bucket name\n",
    "bucket = 'aws-sdk-pandas72023'\n",
    "path = f\"s3://{bucket}/dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS S3 integration\n",
    "\n",
    "##### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_api(ticker:str, start_date:str, end_date:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    tickers(list): List of tickers to be downloaded\n",
    "    start_date(str): Start date of the data\n",
    "    end_date(str): End date of the data\n",
    "    \"\"\"\n",
    "\n",
    "    #Downloading data from yahoo finance api\n",
    "    #If ticker is not available, it will be skipped\n",
    "    #If ticker is available, it will be downloaded and stored in a dataframe\n",
    "    #The dataframe will be returned\n",
    "\n",
    "    try:\n",
    "        ticker = yf.download(tickers=ticker, start=start_date, end=end_date)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return ticker\n",
    "\n",
    "def write_data_to_bucket(file_name:str, mode:str):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    mode(str): Available write modes are 'append', 'overwrite' and 'overwrite_partitions'\n",
    "    \"\"\"\n",
    "\n",
    "    path = f\"s3://{bucket}/raw-data/{file_name}\"\n",
    "    #Sending dataframe of corresponding ticker to bucket\n",
    "    wr.s3.to_csv(\n",
    "        df=df,\n",
    "        path=path,\n",
    "        index=True,\n",
    "        dataset=True,\n",
    "        mode=mode\n",
    "    )\n",
    "\n",
    "def read_csv_from_bucket(folder_name:str) -> pd.DataFrame:\n",
    "\n",
    "    df = wr.s3.read_csv(path = f\"s3://{bucket}/raw-data/{folder_name}/\",\n",
    "                        path_suffix = \".csv\"\n",
    ")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing data to S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading a single dataframe from API and loading to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker = 'NVDA'\n",
    "\n",
    "#Getting data fro API corresponding to the ticker symbol `NVIDIA Corporation`\n",
    "df = get_data_from_api(ticker,start_date,end_date)\n",
    "\n",
    "#Writing data to the bucket\n",
    "write_data_to_bucket(ticker,'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading a multiple dataframes from API and loading to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = ['C', 'CAT', 'CL']\n",
    "\n",
    "for ticker in tickers:\n",
    "    #Downloading data from API\n",
    "    df = get_data_from_api(ticker, start_date, end_date)\n",
    "    #Writing data to the bucket\n",
    "    write_data_to_bucket(ticker,'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading data from bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>178.419998</td>\n",
       "      <td>181.070007</td>\n",
       "      <td>176.479996</td>\n",
       "      <td>180.990005</td>\n",
       "      <td>177.090622</td>\n",
       "      <td>2214500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>181.490005</td>\n",
       "      <td>182.800003</td>\n",
       "      <td>177.339996</td>\n",
       "      <td>178.619995</td>\n",
       "      <td>174.771698</td>\n",
       "      <td>1961500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>179.169998</td>\n",
       "      <td>182.600006</td>\n",
       "      <td>177.770004</td>\n",
       "      <td>181.809998</td>\n",
       "      <td>177.892975</td>\n",
       "      <td>1845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>181.160004</td>\n",
       "      <td>183.649994</td>\n",
       "      <td>180.580002</td>\n",
       "      <td>181.229996</td>\n",
       "      <td>177.325470</td>\n",
       "      <td>1767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>182.919998</td>\n",
       "      <td>186.179993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>185.250000</td>\n",
       "      <td>181.258881</td>\n",
       "      <td>1856500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2023-07-14</td>\n",
       "      <td>256.480011</td>\n",
       "      <td>256.480011</td>\n",
       "      <td>252.910004</td>\n",
       "      <td>255.619995</td>\n",
       "      <td>254.360352</td>\n",
       "      <td>1936800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>254.270004</td>\n",
       "      <td>258.850006</td>\n",
       "      <td>252.009995</td>\n",
       "      <td>257.459991</td>\n",
       "      <td>256.191284</td>\n",
       "      <td>2674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2023-07-18</td>\n",
       "      <td>257.630005</td>\n",
       "      <td>264.160004</td>\n",
       "      <td>256.929993</td>\n",
       "      <td>263.809998</td>\n",
       "      <td>262.509979</td>\n",
       "      <td>3833400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>260.140015</td>\n",
       "      <td>262.920013</td>\n",
       "      <td>259.700012</td>\n",
       "      <td>262.750000</td>\n",
       "      <td>262.750000</td>\n",
       "      <td>2771900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>264.170013</td>\n",
       "      <td>265.399994</td>\n",
       "      <td>260.440002</td>\n",
       "      <td>261.089996</td>\n",
       "      <td>261.089996</td>\n",
       "      <td>2102300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2022-07-21  178.419998  181.070007  176.479996  180.990005  177.090622   \n",
       "1    2022-07-22  181.490005  182.800003  177.339996  178.619995  174.771698   \n",
       "2    2022-07-25  179.169998  182.600006  177.770004  181.809998  177.892975   \n",
       "3    2022-07-26  181.160004  183.649994  180.580002  181.229996  177.325470   \n",
       "4    2022-07-27  182.919998  186.179993  180.320007  185.250000  181.258881   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "246  2023-07-14  256.480011  256.480011  252.910004  255.619995  254.360352   \n",
       "247  2023-07-17  254.270004  258.850006  252.009995  257.459991  256.191284   \n",
       "248  2023-07-18  257.630005  264.160004  256.929993  263.809998  262.509979   \n",
       "249  2023-07-19  260.140015  262.920013  259.700012  262.750000  262.750000   \n",
       "250  2023-07-20  264.170013  265.399994  260.440002  261.089996  261.089996   \n",
       "\n",
       "      Volume  \n",
       "0    2214500  \n",
       "1    1961500  \n",
       "2    1845600  \n",
       "3    1767700  \n",
       "4    1856500  \n",
       "..       ...  \n",
       "246  1936800  \n",
       "247  2674500  \n",
       "248  3833400  \n",
       "249  2771900  \n",
       "250  2102300  \n",
       "\n",
       "[251 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv_from_bucket('CAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr.s3.does_object_exist(f's3://{bucket}/raw-data/CAT/3fc6c37a1c344286b83ecb93e83248a2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
